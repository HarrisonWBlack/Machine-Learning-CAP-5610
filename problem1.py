# -*- coding: utf-8 -*-
"""problem1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yMjghL3TN8jQOrR6E59R7WK_nmz4Vyxg
"""

# Harrison Black
# HA435377
# CAP 5610
# UCF Spring 2019

# Problem 1
# Use logistic regression with mean squared error loss

import tensorflow as tf
from keras.utils import to_categorical
import numpy as np

# Seed random number
np.random.seed(526)

# Sigma Function
def sig_func(z):
  s = 1.0 / (1.0 + np.exp(-z))
  return s

# Calculate Sigma Prime
def sig_prime(z):
  sig_prime = sig_func(z) * (1 - sig_func(z))
  return sig_prime

# Calculate Squared Error Loss
def squared_error(a, y):
  return 0.5 * (a - y) ** 2

# Load data set. 60000 training images, 10000 testing images
mnist = tf.keras.datasets.mnist
(training_imgs, training_labels), (test_imgs, test_labels) = mnist.load_data()

number_of_imgs, num_rows, num_columns = training_imgs.shape

# Image Classifier class
class ImageClassifier:
  def __init__(self, number):
    self.number = number
    self.weight = np.random.randn(num_rows * num_columns, 1)
    self.bias = 0
  
  def model_training(self):
    
#     0.01 = 82.9
#     0.015 = 84.1
#     0.02 = 84.52
#     0.023 = 84.51
#     0.024 = 84.58
#     0.025 = 84.53
#     0.028 = 84.39
#     0.03 = 84.1
#     0.04 = 83.4
#     0.05 = 82.9
#     0.06 = 82
#     0.1 = 79%
#     0.2 = 75%
    
    learning_rate = 0.024

    for i in range(number_of_imgs):
      x = training_imgs[i]
      y = 0
      
      if training_labels[i] == self.number:
        y = 1
 
      z = self.weight.T.dot(x) + self.bias
      a = sig_func(z)
    
#     Plot changes in loss
    
      loss = squared_error(a, y)
      prime_a = sig_prime(a)
      
      self.weight -= learning_rate * (a - y) * prime_a * x
      self.bias -= (a - y) * prime_a * learning_rate * -1
      
  def prediction(self, x):
    prediction = sig_func(self.weight.T.dot(x) + self.bias)
    return prediction

# Reshape data set to vectors
training_imgs = (training_imgs.reshape(number_of_imgs, num_rows * num_columns, 1)).astype('float32') / 255
test_imgs = (test_imgs.reshape(10000, num_rows * num_columns)).astype('float32') / 255

# Create and train each classifier
model_0 = ImageClassifier(0)
model_1 = ImageClassifier(1)
model_2 = ImageClassifier(2)
model_3 = ImageClassifier(3)
model_4 = ImageClassifier(4)
model_5 = ImageClassifier(5)
model_6 = ImageClassifier(6)
model_7 = ImageClassifier(7)
model_8 = ImageClassifier(8)
model_9 = ImageClassifier(9)

model_0.model_training()
model_1.model_training()
model_2.model_training()
model_3.model_training()
model_4.model_training()
model_5.model_training()
model_6.model_training()
model_7.model_training()
model_8.model_training()
model_9.model_training()

# Test accuracy on test images
predictions = []
answer = 0
num_right = 0

for i in range ( len(test_imgs) ):
  predictions.append(model_0.prediction(test_imgs[i]))
  predictions.append(model_1.prediction(test_imgs[i]))
  predictions.append(model_2.prediction(test_imgs[i]))
  predictions.append(model_3.prediction(test_imgs[i]))
  predictions.append(model_4.prediction(test_imgs[i]))
  predictions.append(model_5.prediction(test_imgs[i]))
  predictions.append(model_6.prediction(test_imgs[i]))
  predictions.append(model_7.prediction(test_imgs[i]))
  predictions.append(model_8.prediction(test_imgs[i]))
  predictions.append(model_9.prediction(test_imgs[i]))
  
  answer = np.argmax(predictions)
  predictions.clear()
  
  if(answer == test_labels[i]):
    num_right += 1    

# Print accuracy
print(num_right/len(test_imgs))