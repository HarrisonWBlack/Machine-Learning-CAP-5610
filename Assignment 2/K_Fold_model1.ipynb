{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K-Fold_model1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarrisonWBlack/Machine-Learning-CAP-5610/blob/master/Assignment%202/K_Fold_model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SI4Hm99JVPjU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook fails due to a type error with the validation_data() function inside the model.fit_generator() function.  The parameter for validation_data() expects a tuple, which I am passing in.  However I recieve a type error saying it is not a tuple.  I have bashed my head against this keyboard for the past 4 hours trying to solve this issue, and have gone as far as read the Keras documentation on the function and even page 2 of google.  Please have mercy on me for Keras and Collab have not."
      ]
    },
    {
      "metadata": {
        "id": "boTugGY6OSEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2809
        },
        "outputId": "57b85fab-ee91-42d7-a412-b675a8e1c82e"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras import backend as k\n",
        "\n",
        "k.clear_session()\n",
        "\n",
        "(training_images, training_labels), (testing_images, testing_labels) = cifar10.load_data()\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 25\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "training_labels = keras.utils.to_categorical(training_labels)\n",
        "testing_labels = keras.utils.to_categorical(testing_labels)\n",
        "training_images = training_images.astype(\"float32\") \n",
        "testing_images = testing_images.astype(\"float32\") \n",
        "training_images = training_images.astype(\"float32\") / 255\n",
        "testing_images = testing_images.astype(\"float32\") / 255\n",
        "\n",
        "dropout_rate = 0.2\n",
        "length = 10000\n",
        "accuracy = []\n",
        "for i in range(5):\n",
        "  start = length * i\n",
        "  end = length * (i + 1)\n",
        "  validation_images = training_images[start:end]\n",
        "  validation_labels = training_labels[start:end]\n",
        "  \n",
        "  train_images = np.concatenate((training_images[:start], training_images[end:]))\n",
        "  train_labels = np.concatenate((training_labels[:start], training_labels[end:]))\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  \n",
        "  model.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=\"Adam\",\n",
        "             metrics=[\"accuracy\"])\n",
        "  \n",
        "  datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    zca_epsilon=1e-06,\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.,\n",
        "    zoom_range=0.,\n",
        "    channel_shift_range=0.,\n",
        "    fill_mode=\"nearest\",\n",
        "    cval=0.,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    rescale=None,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    validation_split=0.0)\n",
        "  \n",
        "  datagen.fit(training_images)\n",
        "  model.fit_generator(datagen.flow(training_images, training_labels,\n",
        "                                  batch_size=batch_size),\n",
        "                     epochs=epochs,\n",
        "                     validation_data=(validation_images, validation_labels),\n",
        "                     workers=1)\n",
        "  \n",
        "  score = model.evaluate(testing_images, testing_labels, verbose=0)\n",
        "  accuracy.append(score[1])\n",
        "  k.clear_session()\n",
        "  \n",
        "total = 0.0\n",
        "for k in accuracy:\n",
        "  total += k\n",
        "  \n",
        "avg_score = total / 5\n",
        "print(avg_score)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/25\n",
            "10000/10000 [==============================] - 1s 100us/sample - loss: 3.6139 - acc: 0.1402\n",
            "196/196 [==============================] - 32s 163ms/step - loss: 1.5734 - acc: 0.4411 - val_loss: 3.6331 - val_acc: 0.1402\n",
            "Epoch 2/25\n",
            "10000/10000 [==============================] - 1s 76us/sample - loss: 3.1066 - acc: 0.2307\n",
            "196/196 [==============================] - 29s 146ms/step - loss: 1.2359 - acc: 0.5586 - val_loss: 3.1340 - val_acc: 0.2307\n",
            "Epoch 3/25\n",
            "10000/10000 [==============================] - 1s 81us/sample - loss: 1.5245 - acc: 0.4954\n",
            "196/196 [==============================] - 29s 146ms/step - loss: 1.1111 - acc: 0.6059 - val_loss: 1.5292 - val_acc: 0.4954\n",
            "Epoch 4/25\n",
            "10000/10000 [==============================] - 1s 82us/sample - loss: 1.0642 - acc: 0.6243\n",
            "196/196 [==============================] - 29s 147ms/step - loss: 1.0269 - acc: 0.6343 - val_loss: 1.0731 - val_acc: 0.6243\n",
            "Epoch 5/25\n",
            "10000/10000 [==============================] - 1s 81us/sample - loss: 1.0771 - acc: 0.6432\n",
            "196/196 [==============================] - 29s 146ms/step - loss: 0.9597 - acc: 0.6577 - val_loss: 1.0774 - val_acc: 0.6432\n",
            "Epoch 6/25\n",
            "10000/10000 [==============================] - 1s 76us/sample - loss: 0.7607 - acc: 0.7323\n",
            "196/196 [==============================] - 28s 145ms/step - loss: 0.9095 - acc: 0.6771 - val_loss: 0.7749 - val_acc: 0.7323\n",
            "Epoch 7/25\n",
            "10000/10000 [==============================] - 1s 75us/sample - loss: 0.7387 - acc: 0.7399\n",
            "196/196 [==============================] - 28s 142ms/step - loss: 0.8729 - acc: 0.6923 - val_loss: 0.7448 - val_acc: 0.7399\n",
            "Epoch 8/25\n",
            "10000/10000 [==============================] - 1s 73us/sample - loss: 0.7546 - acc: 0.7383\n",
            "196/196 [==============================] - 28s 142ms/step - loss: 0.8398 - acc: 0.7033 - val_loss: 0.7667 - val_acc: 0.7383\n",
            "Epoch 9/25\n",
            "10000/10000 [==============================] - 1s 76us/sample - loss: 0.7918 - acc: 0.7270\n",
            "196/196 [==============================] - 28s 143ms/step - loss: 0.8159 - acc: 0.7126 - val_loss: 0.8030 - val_acc: 0.7270\n",
            "Epoch 10/25\n",
            "10000/10000 [==============================] - 1s 73us/sample - loss: 0.6445 - acc: 0.7764\n",
            "196/196 [==============================] - 28s 144ms/step - loss: 0.7947 - acc: 0.7200 - val_loss: 0.6535 - val_acc: 0.7764\n",
            "Epoch 11/25\n",
            "10000/10000 [==============================] - 1s 72us/sample - loss: 0.6865 - acc: 0.7606\n",
            "196/196 [==============================] - 28s 144ms/step - loss: 0.7650 - acc: 0.7305 - val_loss: 0.6988 - val_acc: 0.7606\n",
            "Epoch 12/25\n",
            "10000/10000 [==============================] - 1s 76us/sample - loss: 0.6314 - acc: 0.7750\n",
            "196/196 [==============================] - 28s 143ms/step - loss: 0.7501 - acc: 0.7336 - val_loss: 0.6434 - val_acc: 0.7750\n",
            "Epoch 13/25\n",
            "10000/10000 [==============================] - 1s 76us/sample - loss: 0.6598 - acc: 0.7688\n",
            "196/196 [==============================] - 28s 143ms/step - loss: 0.7337 - acc: 0.7422 - val_loss: 0.6700 - val_acc: 0.7688\n",
            "Epoch 14/25\n",
            "10000/10000 [==============================] - 1s 71us/sample - loss: 0.5417 - acc: 0.8079\n",
            "196/196 [==============================] - 28s 143ms/step - loss: 0.7142 - acc: 0.7499 - val_loss: 0.5445 - val_acc: 0.8079\n",
            "Epoch 15/25\n",
            "10000/10000 [==============================] - 1s 74us/sample - loss: 0.5825 - acc: 0.7961\n",
            "196/196 [==============================] - 28s 144ms/step - loss: 0.7067 - acc: 0.7510 - val_loss: 0.5891 - val_acc: 0.7961\n",
            "Epoch 16/25\n",
            "10000/10000 [==============================] - 1s 77us/sample - loss: 0.7887 - acc: 0.7333\n",
            "196/196 [==============================] - 28s 143ms/step - loss: 0.6886 - acc: 0.7580 - val_loss: 0.8071 - val_acc: 0.7333\n",
            "Epoch 17/25\n",
            "10000/10000 [==============================] - 1s 75us/sample - loss: 0.6188 - acc: 0.7825\n",
            "196/196 [==============================] - 28s 143ms/step - loss: 0.6852 - acc: 0.7584 - val_loss: 0.6259 - val_acc: 0.7825\n",
            "Epoch 18/25\n",
            "10000/10000 [==============================] - 1s 74us/sample - loss: 0.6921 - acc: 0.7644\n",
            "196/196 [==============================] - 28s 144ms/step - loss: 0.6617 - acc: 0.7662 - val_loss: 0.6932 - val_acc: 0.7644\n",
            "Epoch 19/25\n",
            "10000/10000 [==============================] - 1s 82us/sample - loss: 0.7177 - acc: 0.7592\n",
            "196/196 [==============================] - 31s 158ms/step - loss: 0.6492 - acc: 0.7739 - val_loss: 0.7222 - val_acc: 0.7592\n",
            "Epoch 20/25\n",
            "10000/10000 [==============================] - 1s 117us/sample - loss: 0.6029 - acc: 0.7898\n",
            "196/196 [==============================] - 54s 278ms/step - loss: 0.6540 - acc: 0.7717 - val_loss: 0.6075 - val_acc: 0.7898\n",
            "Epoch 21/25\n",
            "10000/10000 [==============================] - 1s 105us/sample - loss: 0.6660 - acc: 0.7734\n",
            "196/196 [==============================] - 54s 276ms/step - loss: 0.6450 - acc: 0.7724 - val_loss: 0.6744 - val_acc: 0.7734\n",
            "Epoch 22/25\n",
            "10000/10000 [==============================] - 1s 115us/sample - loss: 0.6148 - acc: 0.7876\n",
            "196/196 [==============================] - 57s 293ms/step - loss: 0.6273 - acc: 0.7785 - val_loss: 0.6206 - val_acc: 0.7876\n",
            "Epoch 23/25\n",
            "10000/10000 [==============================] - 1s 109us/sample - loss: 0.5893 - acc: 0.8010\n",
            "196/196 [==============================] - 57s 289ms/step - loss: 0.6224 - acc: 0.7797 - val_loss: 0.5976 - val_acc: 0.8010\n",
            "Epoch 24/25\n",
            "10000/10000 [==============================] - 1s 81us/sample - loss: 0.4670 - acc: 0.8390\n",
            "196/196 [==============================] - 44s 222ms/step - loss: 0.6189 - acc: 0.7837 - val_loss: 0.4782 - val_acc: 0.8390\n",
            "Epoch 25/25\n",
            "10000/10000 [==============================] - 1s 79us/sample - loss: 0.4355 - acc: 0.8447\n",
            "196/196 [==============================] - 28s 145ms/step - loss: 0.6087 - acc: 0.7867 - val_loss: 0.4403 - val_acc: 0.8447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1092\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3556\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder:0\", shape=(), dtype=float32) is not an element of this graph.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-074af34aa73d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                      workers=1)\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# Setup work for each epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0mtraining_distributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \"\"\"\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m       \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mset_value\u001b[0;34m(x, value)\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2847\u001b[0;31m       \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1095\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(), dtype=float32) is not an element of this graph."
          ]
        }
      ]
    }
  ]
}