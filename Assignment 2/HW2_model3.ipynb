{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_model3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarrisonWBlack/Machine-Learning-CAP-5610/blob/master/Assignment%202/HW2_model3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "w7ot5-711H2Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Six layer, dropout, with batch normalization and data augmentation at 25epochs**\n",
        "This model behaves poorly do to over overfitting."
      ]
    },
    {
      "metadata": {
        "id": "PW9HYv5yfm_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "(training_images, training_labels), (testing_images, testing_labels) = cifar10.load_data()\n",
        "batch_size = 256\n",
        "epochs = 25\n",
        "augment_data = True\n",
        "training_labels = keras.utils.to_categorical(training_labels)\n",
        "testing_labels = keras.utils.to_categorical(testing_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "10QKnrDMja54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dropout_rate = 0.2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=training_images.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(dropout_rate))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(dropout_rate))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(dropout_rate))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(2 * dropout_rate))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(2 * dropout_rate))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vN_SUvYllw2e",
        "colab_type": "code",
        "outputId": "118e9309-b7be-488f-9427-27b2c0d53ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1320
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=\"Adam\",\n",
        "             metrics=[\"accuracy\"])\n",
        "\n",
        "training_images = training_images.astype(\"float32\") / 255\n",
        "testing_images = testing_images.astype(\"float32\") / 255\n",
        "\n",
        "if not augment_data:\n",
        "  model.fit(training_images, training_labels,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           validation_data=(testing_images, testing_labels),\n",
        "           shuffle=True)\n",
        "  \n",
        "else:\n",
        "  datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    zca_epsilon=1e-06,\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.,\n",
        "    zoom_range=0.,\n",
        "    channel_shift_range=0.,\n",
        "    fill_mode=\"nearest\",\n",
        "    cval=0.,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    rescale=None,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    validation_split=0.0)\n",
        "  \n",
        "  datagen.fit(training_images)\n",
        "  model.fit_generator(datagen.flow(training_images, training_labels,\n",
        "                                  batch_size=batch_size),\n",
        "                     epochs=epochs,\n",
        "                     validation_data=(testing_images, testing_labels),\n",
        "                     workers=1)\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "10000/10000 [==============================] - 1s 137us/sample - loss: 3.1250 - acc: 0.1058\n",
            "196/196 [==============================] - 53s 271ms/step - loss: 1.9939 - acc: 0.3240 - val_loss: 3.1261 - val_acc: 0.1058\n",
            "Epoch 2/25\n",
            "10000/10000 [==============================] - 1s 114us/sample - loss: 2.2251 - acc: 0.2649\n",
            "196/196 [==============================] - 53s 271ms/step - loss: 1.5247 - acc: 0.4441 - val_loss: 2.2333 - val_acc: 0.2649\n",
            "Epoch 3/25\n",
            "10000/10000 [==============================] - 1s 116us/sample - loss: 1.1999 - acc: 0.5765\n",
            "196/196 [==============================] - 53s 271ms/step - loss: 1.3566 - acc: 0.5106 - val_loss: 1.1964 - val_acc: 0.5765\n",
            "Epoch 4/25\n",
            "10000/10000 [==============================] - 1s 114us/sample - loss: 1.2098 - acc: 0.5716\n",
            "196/196 [==============================] - 53s 268ms/step - loss: 1.2615 - acc: 0.5472 - val_loss: 1.2049 - val_acc: 0.5716\n",
            "Epoch 5/25\n",
            "10000/10000 [==============================] - 1s 114us/sample - loss: 1.0166 - acc: 0.6317\n",
            "196/196 [==============================] - 52s 266ms/step - loss: 1.1919 - acc: 0.5766 - val_loss: 1.0168 - val_acc: 0.6317\n",
            "Epoch 6/25\n",
            "10000/10000 [==============================] - 1s 95us/sample - loss: 1.0333 - acc: 0.6388\n",
            "196/196 [==============================] - 51s 261ms/step - loss: 1.1286 - acc: 0.5981 - val_loss: 1.0323 - val_acc: 0.6388\n",
            "Epoch 7/25\n",
            "10000/10000 [==============================] - 1s 97us/sample - loss: 0.9645 - acc: 0.6550\n",
            "196/196 [==============================] - 51s 260ms/step - loss: 1.0801 - acc: 0.6175 - val_loss: 0.9581 - val_acc: 0.6550\n",
            "Epoch 8/25\n",
            "10000/10000 [==============================] - 1s 98us/sample - loss: 1.0219 - acc: 0.6385\n",
            "196/196 [==============================] - 50s 255ms/step - loss: 1.0374 - acc: 0.6360 - val_loss: 1.0286 - val_acc: 0.6385\n",
            "Epoch 9/25\n",
            "10000/10000 [==============================] - 1s 98us/sample - loss: 1.4479 - acc: 0.5393\n",
            "196/196 [==============================] - 51s 259ms/step - loss: 1.0107 - acc: 0.6453 - val_loss: 1.4364 - val_acc: 0.5393\n",
            "Epoch 10/25\n",
            "10000/10000 [==============================] - 1s 101us/sample - loss: 1.0014 - acc: 0.6510\n",
            "196/196 [==============================] - 53s 270ms/step - loss: 0.9812 - acc: 0.6563 - val_loss: 0.9904 - val_acc: 0.6510\n",
            "Epoch 11/25\n",
            "10000/10000 [==============================] - 1s 100us/sample - loss: 0.9873 - acc: 0.6589\n",
            "196/196 [==============================] - 53s 272ms/step - loss: 0.9562 - acc: 0.6655 - val_loss: 0.9827 - val_acc: 0.6589\n",
            "Epoch 12/25\n",
            "10000/10000 [==============================] - 1s 104us/sample - loss: 1.1013 - acc: 0.6391\n",
            "196/196 [==============================] - 52s 267ms/step - loss: 0.9306 - acc: 0.6743 - val_loss: 1.0887 - val_acc: 0.6391\n",
            "Epoch 13/25\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.7653 - acc: 0.7268\n",
            "196/196 [==============================] - 52s 266ms/step - loss: 0.9081 - acc: 0.6859 - val_loss: 0.7609 - val_acc: 0.7268\n",
            "Epoch 14/25\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.8761 - acc: 0.6971\n",
            "196/196 [==============================] - 52s 264ms/step - loss: 0.8946 - acc: 0.6885 - val_loss: 0.8649 - val_acc: 0.6971\n",
            "Epoch 15/25\n",
            "10000/10000 [==============================] - 1s 100us/sample - loss: 0.7363 - acc: 0.7441\n",
            "196/196 [==============================] - 50s 255ms/step - loss: 0.8765 - acc: 0.6969 - val_loss: 0.7315 - val_acc: 0.7441\n",
            "Epoch 16/25\n",
            "10000/10000 [==============================] - 1s 118us/sample - loss: 0.8353 - acc: 0.7060\n",
            "196/196 [==============================] - 54s 278ms/step - loss: 0.8594 - acc: 0.7020 - val_loss: 0.8250 - val_acc: 0.7060\n",
            "Epoch 17/25\n",
            "10000/10000 [==============================] - 1s 101us/sample - loss: 0.7658 - acc: 0.7301\n",
            "196/196 [==============================] - 52s 267ms/step - loss: 0.8523 - acc: 0.7044 - val_loss: 0.7589 - val_acc: 0.7301\n",
            "Epoch 18/25\n",
            "10000/10000 [==============================] - 1s 105us/sample - loss: 0.8674 - acc: 0.7054\n",
            "196/196 [==============================] - 52s 264ms/step - loss: 0.8416 - acc: 0.7089 - val_loss: 0.8592 - val_acc: 0.7054\n",
            "Epoch 19/25\n",
            "10000/10000 [==============================] - 1s 117us/sample - loss: 0.7473 - acc: 0.7437\n",
            "196/196 [==============================] - 52s 265ms/step - loss: 0.8241 - acc: 0.7139 - val_loss: 0.7434 - val_acc: 0.7437\n",
            "Epoch 20/25\n",
            "10000/10000 [==============================] - 1s 100us/sample - loss: 0.7003 - acc: 0.7545\n",
            "196/196 [==============================] - 51s 259ms/step - loss: 0.8207 - acc: 0.7167 - val_loss: 0.6978 - val_acc: 0.7545\n",
            "Epoch 21/25\n",
            "10000/10000 [==============================] - 1s 88us/sample - loss: 0.8205 - acc: 0.7249\n",
            "196/196 [==============================] - 51s 258ms/step - loss: 0.8095 - acc: 0.7193 - val_loss: 0.8180 - val_acc: 0.7249\n",
            "Epoch 22/25\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.6706 - acc: 0.7698\n",
            "196/196 [==============================] - 51s 260ms/step - loss: 0.7968 - acc: 0.7234 - val_loss: 0.6678 - val_acc: 0.7698\n",
            "Epoch 23/25\n",
            "10000/10000 [==============================] - 1s 103us/sample - loss: 0.6625 - acc: 0.7655\n",
            "196/196 [==============================] - 51s 261ms/step - loss: 0.7858 - acc: 0.7273 - val_loss: 0.6571 - val_acc: 0.7655\n",
            "Epoch 24/25\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.7623 - acc: 0.7315\n",
            "196/196 [==============================] - 53s 270ms/step - loss: 0.7818 - acc: 0.7263 - val_loss: 0.7653 - val_acc: 0.7315\n",
            "Epoch 25/25\n",
            "10000/10000 [==============================] - 1s 81us/sample - loss: 0.7625 - acc: 0.7394\n",
            "196/196 [==============================] - 38s 192ms/step - loss: 0.7734 - acc: 0.7317 - val_loss: 0.7603 - val_acc: 0.7394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZXwN7oG1q3mP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Decent model."
      ]
    },
    {
      "metadata": {
        "id": "IThBqEX3rhI3",
        "colab_type": "code",
        "outputId": "c3053bcf-6fca-4659-ea46-f40ef948f0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(testing_images, testing_labels, verbose=1)\n",
        "print(\"Test loss: \", scores[0])\n",
        "print(\"Test accuracy: \", scores[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 156us/sample - loss: 0.7626 - acc: 0.7394\n",
            "Test loss:  0.7625530331611633\n",
            "Test accuracy:  0.7394\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}