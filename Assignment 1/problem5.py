# -*- coding: utf-8 -*-
"""problem5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FvGVVwsijhmDtVx3ERRVHPhFsY5mesUX
"""

# Harrison Black
# HA435377
# CAP 5610
# UCF Spring 2019

# Problem 5
# Add features to problem 4

import tensorflow as tf
from keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
from keras import models

mnist = tf.keras.datasets.mnist
(training_imgs, training_labels), (test_imgs, test_labels) = mnist.load_data()
number_of_imgs, num_rows, num_columns = training_imgs.shape

def count_connected_regions(img):
  
  # Round all grey values
  img = np.around(img)
  
  # Value of previous pixel
  prev_pixel = 0
  
  # Current region
  region_number = 1
  
  # Zeros in the region array signify black pixels once comleted
  region_array = np.full_like(img, 0)
  
  # Go through each pixel
  for pixel in range(len(img)):
    
    # Only count on white pixels
    if img[pixel] == 0:
      region_array[pixel] = region_number
      
    # If pixel goes from white to black, region_number += 1
    elif img[pixel] == 1 and prev_pixel == 0:
      region_number += 1

    # Set prev pixel to current pixel and loop
    prev_pixel = img[pixel]

  # Loop through again to join touching regions
  for pixel in range(len(img)):
    
    # Don't go out of bounds
    if(pixel + 28 < len(img)):
      
      # Each row is 28 long. If you skip ahead 28 pixels you are looking at the next row 
      # If two non white pixels in different rows are touching, they are in the same region
      if(region_array[pixel] != region_array[pixel + 28] and region_array[pixel] != 0 and region_array[pixel + 28] != 0):
        region_array[region_array == region_array[pixel + 28]] = region_array[pixel]

  # Return the number of unique values in the region_array excluding the value for black pixels (0) 
  return len(np.unique(region_array)) - 1

training_imgs = (training_imgs.reshape(number_of_imgs, num_rows * num_columns, 1)).astype('float32') / 255
test_imgs = (test_imgs.reshape(len(test_imgs), num_rows * num_columns, 1)).astype('float32') / 255

def append_region_count(imgs):
  appended_imgs = []
  for i in range(len(imgs)):
    appended_imgs.append(np.append(imgs[i], count_connected_regions(imgs[i])))
  return appended_imgs

appended_training_imgs = append_region_count(training_imgs)
appended_test_imgs = append_region_count(test_imgs)

print("Appending completed")

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(np.array(appended_training_imgs), training_labels, epochs=3)
loss_value, accuracy_value = model.evaluate(np.array(appended_test_imgs), test_labels)
print("Loss value: ", loss_value, "\nModel accuracy: ", accuracy_value)