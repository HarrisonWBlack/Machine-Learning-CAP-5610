{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problem5_colab.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZS0GFZDrb3bD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Problem 5:\n",
        "Adding additional features to problem number 4"
      ]
    },
    {
      "metadata": {
        "id": "p36G7DhGcDkY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load in the training and test images."
      ]
    },
    {
      "metadata": {
        "id": "cC6_XNBLd5_C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Harrison Black\n",
        "# HA435377\n",
        "# CAP 5610\n",
        "# UCF Spring 2019\n",
        "\n",
        "# Problem 5\n",
        "# Add features to problem 4\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_imgs, training_labels), (test_imgs_og, test_labels) = mnist.load_data()\n",
        "number_of_imgs, num_rows, num_columns = training_imgs.shape\n",
        "\n",
        "training_imgs = (training_imgs.reshape(number_of_imgs, num_rows * num_columns, 1)).astype('float32') / 255\n",
        "test_imgs = (test_imgs_og.reshape(len(test_imgs_og), num_rows * num_columns, 1)).astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qV2UzmNicG8L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Functions for finding features and concatenating them to the end of the image array.\n",
        "Finds number of white regions for a digit, the digit width, and the digit height."
      ]
    },
    {
      "metadata": {
        "id": "Pqp4Ep7AbZGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1488122-af8b-4f9d-ad00-1161808c1e86"
      },
      "cell_type": "code",
      "source": [
        "# Find the number of unique regions, the width, and the height of a given digit\n",
        "def get_features(img):\n",
        "  \n",
        "  # Empty list to store features\n",
        "  features = []\n",
        "  \n",
        "  # Round all grey values\n",
        "  img = np.around(img)\n",
        "  \n",
        "  # Value of previous pixel\n",
        "  prev_pixel = 0\n",
        "  \n",
        "  # Current region\n",
        "  region_number = 1\n",
        "  \n",
        "  # Zeros in the region array signify black pixels once comleted\n",
        "  region_array = np.full_like(img, 0)\n",
        "  \n",
        "  # Values to help determine the width of a digit\n",
        "  first_in_row = True\n",
        "  first_black_pixel_in_row = 0\n",
        "  last_black_pixel_in_row = 0\n",
        "  longest_range = 0\n",
        "  \n",
        "  # Values to help determine height\n",
        "  top_pixel = 0\n",
        "  bottom_pixel = 0\n",
        "  found_first = False\n",
        "  \n",
        "  # NOTE: Below both the unique number of regions,the width and the height are found in the same loop\n",
        "  #       This helps to speed up run time\n",
        "  \n",
        "  # Go through each pixel\n",
        "  for pixel in range(len(img)):\n",
        "    \n",
        "    # Labeling regions at start of loop\n",
        "    \n",
        "    # Only count on white pixels\n",
        "    if img[pixel] == 0:\n",
        "      region_array[pixel] = region_number\n",
        "      \n",
        "    # If pixel goes from white to black, region_number += 1\n",
        "    elif img[pixel] == 1 and prev_pixel == 0:\n",
        "      region_number += 1\n",
        "\n",
        "    # Set prev pixel to current pixel and loop\n",
        "    prev_pixel = img[pixel]\n",
        "    \n",
        "    # Determining width and height for the rest of the loop\n",
        "    # To account for width, keep track of the first black pixel in a row and the last black pixel in a row. The longest span is the width.\n",
        "    # To account for height, go through the array and mark the first an last black pixel\n",
        "    \n",
        "    # If we are in a new row\n",
        "    if pixel % 28 == 0:\n",
        "    \n",
        "      # Determine if the previous row had a larger width than the current largest width\n",
        "      if last_black_pixel_in_row - first_black_pixel_in_row > longest_range:\n",
        "        longest_range = last_black_pixel_in_row - first_black_pixel_in_row\n",
        "\n",
        "      # Reset for new row\n",
        "      first_black_pixel_in_row = 0\n",
        "      last_black_pixel_in_row = 0\n",
        "      first_in_row = True\n",
        "    \n",
        "    # If we found the first black pixel\n",
        "    if img[pixel] == 1 and first_in_row:\n",
        "      first_black_pixel_in_row = pixel % 28\n",
        "      first_in_row = False\n",
        "\n",
        "    # If a black pixel\n",
        "    if img[pixel] == 1:\n",
        "      last_black_pixel_in_row = pixel % 28\n",
        "      bottom_pixel = pixel\n",
        "      \n",
        "    if img[pixel] == 1 and not found_first:\n",
        "      top_pixel = pixel\n",
        "      found_first = True\n",
        "\n",
        "  # Finish determining unique regions\n",
        "  # Loop through again to join touching regions\n",
        "  for pixel in range(len(img)):\n",
        "    \n",
        "    # Don't go out of bounds\n",
        "    if(pixel + 28 < len(img)):\n",
        "      \n",
        "      # Each row is 28 long. If you skip ahead 28 pixels you are looking at the next row \n",
        "      # If two non white pixels in different rows are touching, they are in the same region\n",
        "      if(region_array[pixel] != region_array[pixel + 28] and region_array[pixel] != 0 and region_array[pixel + 28] != 0):\n",
        "        region_array[region_array == region_array[pixel + 28]] = region_array[pixel]\n",
        "        \n",
        "  midline = num_columns // 2\n",
        "\n",
        "  # Return the number of unique values in the region_array excluding the value for black pixels (0)#   print(np.unique(region_array) ) \n",
        "  number_of_regions = len(np.unique(region_array)) - 1\n",
        "  \n",
        "  # The width is the longest range of black pixels found\n",
        "  width = longest_range\n",
        "  \n",
        "  # The height is the distance between the first black pixel found and the last black pixel found minus their distance to the midline of the picture\n",
        "  height = ((bottom_pixel - top_pixel) - abs(midline - (top_pixel % 28)) - abs(midline - (bottom_pixel % 28))) / 28\n",
        "  \n",
        "  features.append(number_of_regions)\n",
        "  features.append(width)\n",
        "  features.append(height)\n",
        "\n",
        "  return features\n",
        "\n",
        "# Append the addition features to the end of each image\n",
        "def append_features(imgs):\n",
        "  appended_imgs = []\n",
        "  for i in range(len(imgs)):\n",
        "    features = np.array(get_features(imgs[i]))\n",
        "    features = features.reshape(features.size, 1)\n",
        "    appended_imgs.append(np.concatenate([imgs[i], features]))\n",
        "  return appended_imgs\n",
        "\n",
        "appended_training_imgs = append_features(training_imgs)\n",
        "appended_test_imgs = append_features(test_imgs)\n",
        "print(\"Appending completed\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Appending completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4RfHRluimXyg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model using Keras and determine and display it's overall loss and accuracy."
      ]
    },
    {
      "metadata": {
        "id": "dblwzPukmOHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7d471465-304e-4483-cd00-bbd3aa0ac5a0"
      },
      "cell_type": "code",
      "source": [
        "# Train the model using Keras\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(np.array(appended_training_imgs), training_labels, epochs=3)\n",
        "loss_value, accuracy_value = model.evaluate(np.array(appended_test_imgs), test_labels)\n",
        "\n",
        "print(\"\\nOverall model performance\")\n",
        "print(\"Loss value: \", loss_value, \"\\nModel accuracy: \", accuracy_value)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.6827 - acc: 0.8292\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3777 - acc: 0.9022\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3285 - acc: 0.9105\n",
            "10000/10000 [==============================] - 0s 31us/sample - loss: 0.2946 - acc: 0.9204\n",
            "\n",
            "Overall model performance\n",
            "Loss value:  0.29463275770545005 \n",
            "Model accuracy:  0.9204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J6OWuibdchLJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show an example prediction and display feature data."
      ]
    },
    {
      "metadata": {
        "id": "FlMKugPebqZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "35e2b823-f419-4a74-e90b-4a513e06e7eb"
      },
      "cell_type": "code",
      "source": [
        "# Seed and create random number to test a random image\n",
        "np.random.seed()\n",
        "test_index = np.random.randint(0, len(test_imgs), size=None)\n",
        "\n",
        "print(\"\\nExample prediction: \")\n",
        "plt.imshow(test_imgs_og[test_index], cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "example_digit = np.array(appended_test_imgs[test_index])\n",
        "example_prediction = model.predict([appended_test_imgs])\n",
        "example_features = get_features(appended_test_imgs[test_index])\n",
        "\n",
        "print(\"Actual number: \", test_labels[test_index])\n",
        "print(\"Predicted number: \", np.argmax(example_prediction[test_index]))\n",
        "print(\"Number of white regions: \", example_features[0], \"\\nDigit width: \", example_features[1], \"\\nDigit height: \", example_features[2])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Example prediction: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRNv9plWLPwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Actual number:  7\n",
            "Predicted number:  7\n",
            "Number of white regions:  1 \n",
            "Digit width:  12 \n",
            "Digit height:  21.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}