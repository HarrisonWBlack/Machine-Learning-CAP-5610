{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem1_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarrisonWBlack/Machine-Learning-CAP-5610/blob/master/Assignment%201/Problem1_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uAMvB2e4fS3n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 1: Use logistic regression with mean squared error loss.**"
      ]
    },
    {
      "metadata": {
        "id": "7gZp3iodfhtM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load in the training and test images"
      ]
    },
    {
      "metadata": {
        "id": "_Dn6XHDvdBNn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Problem 1\n",
        "# Use logistic regression with mean squared error loss\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load data set. 60000 training images, 10000 testing images\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_imgs, training_labels), (test_imgs_og, test_labels) = mnist.load_data()\n",
        "\n",
        "number_of_imgs, num_rows, num_columns = training_imgs.shape\n",
        "\n",
        "# Reshape data set to vectors\n",
        "training_imgs = (training_imgs.reshape(number_of_imgs, num_rows * num_columns, 1)).astype('float32') / 255\n",
        "test_imgs = (test_imgs_og.reshape(len(test_imgs_og), num_rows * num_columns)).astype('float32') / 255\n",
        "\n",
        "# Seed random number\n",
        "np.random.seed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZN1U9tL5flC_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function and class definitions"
      ]
    },
    {
      "metadata": {
        "id": "Ij0Rgzg9d7YU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sigma Function\n",
        "def sig_func(z):\n",
        "  s = 1.0 / (1.0 + np.exp(-z))\n",
        "  return s\n",
        "\n",
        "# Calculate Sigma Prime\n",
        "def sig_prime(z):\n",
        "  sig_prime = sig_func(z) * (1 - sig_func(z))\n",
        "  return sig_prime\n",
        "\n",
        "# Calculate Squared Error Loss\n",
        "def squared_error(a, y):\n",
        "  return 0.5 * (a - y) ** 2\n",
        "\n",
        "# Image Classifier class\n",
        "class ImageClassifier:\n",
        "  def __init__(self, number):\n",
        "    self.number = number\n",
        "    self.weight = np.random.randn(num_rows * num_columns, 1)\n",
        "    self.bias = 0\n",
        "    self.loss = 0\n",
        "  \n",
        "  def model_training(self):\n",
        "    \n",
        "    learning_rate = 0.024\n",
        "\n",
        "    for i in range(number_of_imgs):\n",
        "      x = training_imgs[i]\n",
        "      y = 0\n",
        "      \n",
        "      if training_labels[i] == self.number:\n",
        "        y = 1\n",
        "\n",
        "      z = self.weight.T.dot(x) + self.bias\n",
        "      a = sig_func(z)\n",
        "      self.loss = squared_error(a, y)\n",
        "      prime_a = sig_prime(a)\n",
        "      \n",
        "      self.weight -= learning_rate * (a - y) * prime_a * x\n",
        "      self.bias -= (a - y) * prime_a * learning_rate\n",
        "      \n",
        "  def prediction(self, x):\n",
        "    prediction = sig_func(self.weight.T.dot(x) + self.bias)\n",
        "    return prediction\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1VSx31aHfs1h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create and traing each classifier, 0-9."
      ]
    },
    {
      "metadata": {
        "id": "8nTDkPvPeEdP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create and train each classifier\n",
        "models = []\n",
        "for digit in range(10):\n",
        "  models.append(ImageClassifier(digit))\n",
        "  models[digit].model_training()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ws0lNEEBfzCG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test the model on the training imgs to determine it's accuracy. Show an example prediction."
      ]
    },
    {
      "metadata": {
        "id": "0fG3QNkzeQ5s",
        "colab_type": "code",
        "outputId": "2a43e65c-65e0-4e8c-9532-4d6b26968959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "cell_type": "code",
      "source": [
        "# Test accuracy on test images\n",
        "predictions = []\n",
        "answer = 0\n",
        "num_right = 0\n",
        "\n",
        "for i in range ( len(test_imgs) ):\n",
        "  for j in range(len(models)):\n",
        "     predictions.append(models[j].prediction(test_imgs[i]))\n",
        "      \n",
        "  answer = np.argmax(predictions)\n",
        "  predictions.clear()\n",
        "  \n",
        "  if(answer == test_labels[i]):\n",
        "    num_right += 1    \n",
        "\n",
        "# Example predictions\n",
        "print(\"Example prediction: \")\n",
        "test_index = np.random.randint(0, len(test_imgs), size=None)\n",
        "example_predictions = []\n",
        "\n",
        "for k in range(len(models)):\n",
        "  example_predictions.append(models[k].prediction(test_imgs[test_index]))\n",
        "      \n",
        "example_answer = np.argmax(example_predictions)\n",
        "\n",
        "plt.imshow(test_imgs_og[test_index])\n",
        "plt.show()\n",
        "\n",
        "print(\"Actual number: \", test_labels[test_index])\n",
        "print(\"Predicted number: \", example_answer)\n",
        "\n",
        "print()\n",
        "for i in range(10):\n",
        "  print(\"Model \", i, \" loss value: \", models[i].loss )\n",
        "\n",
        "print(\"\\nOverall accuracy across all models: \", round(num_right/len(test_imgs) * 100, 2), \"%\")\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example prediction: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Actual number:  1\n",
            "Predicted number:  1\n",
            "\n",
            "Model  0  loss value:  [[0.0117097]]\n",
            "Model  1  loss value:  [[2.69247358e-15]]\n",
            "Model  2  loss value:  [[2.20704494e-10]]\n",
            "Model  3  loss value:  [[4.32786107e-12]]\n",
            "Model  4  loss value:  [[4.28963144e-18]]\n",
            "Model  5  loss value:  [[5.72450575e-05]]\n",
            "Model  6  loss value:  [[1.83662924e-14]]\n",
            "Model  7  loss value:  [[3.86130462e-07]]\n",
            "Model  8  loss value:  [[0.00040079]]\n",
            "Model  9  loss value:  [[0.00295697]]\n",
            "\n",
            "Overall accuracy across all models:  87.26 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}